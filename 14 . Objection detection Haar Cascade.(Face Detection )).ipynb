{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2785e53d-0f8d-4a37-89d0-bfef547bb313",
   "metadata": {},
   "source": [
    "#  14 . Objection detection Haar Cascade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6dae942d-93d7-42b6-b0bb-db0ce788b8eb",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import cv2\n",
    "\n",
    "# Load the Haar Cascade classifier\n",
    "face_cascade = cv2.CascadeClassifier(cv2.data.haarcascades + \"haarcascade_frontalface_default.xml\")\n",
    "\n",
    "# Load the input image\n",
    "image = cv2.imread(\"WhatsApp Image 2024-08-30 at 10.03.11 PM.jpeg\")\n",
    "image = cv2.resize(image , (500,500))\n",
    "\n",
    "# Convert the image to grayscale\n",
    "gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "# Detect faces in the image\n",
    "faces = face_cascade.detectMultiScale(gray, scaleFactor=1.1, minNeighbors=5, minSize=(30, 30))\n",
    "\n",
    "# Draw rectangles around the detected faces\n",
    "for (x, y, w, h) in faces:\n",
    "    cv2.rectangle(image, (x, y), (x + w, y + h), (0, 255, 0), 2)  # Green rectangle\n",
    "\n",
    "# Display the result\n",
    "cv2.imshow(\"Detected Faces\", image)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n",
    "\n",
    "# Save the output (optional)\n",
    "cv2.imwrite(\"output_faces.jpg\", image)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa928561-d065-4a77-bdff-95f4c059600b",
   "metadata": {},
   "source": [
    "# Face Detection "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ec77ed49-6dbd-4e6e-a13e-3f70c48bebf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "\n",
    "# Load the Haar Cascade classifier for face detection\n",
    "face_cascade = cv2.CascadeClassifier(cv2.data.haarcascades + \"haarcascade_frontalface_default.xml\")\n",
    "\n",
    "# Initialize the webcam (0 for the default camera)\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "# Check if the webcam is opened correctly\n",
    "if not cap.isOpened():\n",
    "    print(\"Error: Could not open webcam.\")\n",
    "    exit()\n",
    "\n",
    "while True:\n",
    "    # Read a frame from the webcam\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        print(\"Error: Could not read frame.\")\n",
    "        break\n",
    "\n",
    "    # Convert the frame to grayscale for face detection\n",
    "    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    # Detect faces in the frame\n",
    "    faces = face_cascade.detectMultiScale(gray, scaleFactor=1.1, minNeighbors=5, minSize=(30, 30))\n",
    "\n",
    "    # Draw rectangles around the detected faces\n",
    "    for (x, y, w, h) in faces:\n",
    "        cv2.rectangle(frame, (x, y), (x + w, y + h), (0, 255, 0), 3)  # Green rectangle\n",
    "\n",
    "    # Display the frame with detected faces\n",
    "    cv2.imshow(\"Real-Time Face Detection\", frame)\n",
    "\n",
    "    # Break the loop if the 'q' key is pressed\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "# Release the webcam and close the window\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cffe3d9-aff6-41e3-9a3f-667498c6dc39",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e9e90518-ad96-4320-9193-d9238963a82f",
   "metadata": {},
   "source": [
    "# Displaying  coordinates and color code of the points clicked on the image "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "20495678-66c9-4b4d-b24d-908c1c7baf1d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Coordinates: (X: 308, Y: 155)\n",
      "Color (BGR): [159 191 252]\n",
      "Coordinates: (X: 144, Y: 61)\n",
      "Color (BGR): [157 180 230]\n",
      "Coordinates: (X: 193, Y: 128)\n",
      "Color (BGR): [207 218 240]\n",
      "Coordinates: (X: 312, Y: 282)\n",
      "Color (BGR): [216 219 234]\n",
      "Coordinates: (X: 233, Y: 263)\n",
      "Color (BGR): [186 194 217]\n",
      "Coordinates: (X: 275, Y: 411)\n",
      "Color (BGR): [ 98 143 224]\n",
      "Coordinates: (X: 233, Y: 403)\n",
      "Color (BGR): [108 150 225]\n",
      "Coordinates: (X: 89, Y: 296)\n",
      "Color (BGR): [166 188 244]\n",
      "Coordinates: (X: 58, Y: 391)\n",
      "Color (BGR): [29 22 23]\n",
      "Coordinates: (X: 57, Y: 345)\n",
      "Color (BGR): [21 16 18]\n",
      "Coordinates: (X: 122, Y: 182)\n",
      "Color (BGR): [193 208 240]\n",
      "Coordinates: (X: 75, Y: 107)\n",
      "Color (BGR): [178 196 239]\n",
      "Coordinates: (X: 68, Y: 358)\n",
      "Color (BGR): [32 25 28]\n",
      "Coordinates: (X: 70, Y: 373)\n",
      "Color (BGR): [30 25 27]\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "\n",
    "# Function to display coordinates and color on mouse click\n",
    "def click_event(event, x, y, flags, param):\n",
    "    if event == cv2.EVENT_LBUTTONDOWN:  # Left mouse button click\n",
    "        # Display coordinates\n",
    "        print(f\"Coordinates: (X: {x}, Y: {y})\")\n",
    "        \n",
    "        # Display BGR color code\n",
    "        color = image[y, x]  # Get color at the clicked position\n",
    "        print(f\"Color (BGR): {color}\")\n",
    "        \n",
    "        # Annotate the image with coordinates and color\n",
    "        text = f\"{x},{y} {color.tolist()}\"\n",
    "        cv2.putText(image, text, (x, y), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 0), 1)\n",
    "        cv2.imshow(\"Image\", image)\n",
    "\n",
    "# Load the image\n",
    "image = cv2.imread(\"WhatsApp Image 2024-08-30 at 10.03.11 PM.jpeg\")\n",
    "image = cv2.resize(image , (500, 500))\n",
    "cv2.imshow(\"Image\", image)\n",
    "\n",
    "# Set mouse callback function\n",
    "cv2.setMouseCallback(\"Image\", click_event)\n",
    "\n",
    "# Wait indefinitely until a key is pressed\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7802984d-3a2d-45fd-b95e-6de60c84199a",
   "metadata": {},
   "source": [
    " # Play a video in reverse mode in opencv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "442ee867-e1bc-42f8-9333-048a7c89d206",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "\n",
    "# Load the video file\n",
    "video_path = \"mixkit-man-and-woman-jogging-together-on-the-street-40881-hd-ready.mp4\"  # Replace with your video file path\n",
    "cap = cv2.VideoCapture(video_path)\n",
    "\n",
    "# Check if the video is loaded successfully\n",
    "if not cap.isOpened():\n",
    "    print(\"Error: Cannot open the video file.\")\n",
    "    exit()\n",
    "\n",
    "# Get the total number of frames in the video\n",
    "total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "\n",
    "# Play the video in reverse\n",
    "for frame_num in range(total_frames - 1, -1, -1):\n",
    "    # Set the current frame position\n",
    "    cap.set(cv2.CAP_PROP_POS_FRAMES, frame_num)\n",
    "\n",
    "    # Read the frame\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        print(f\"Error: Cannot read frame {frame_num}.\")\n",
    "        break\n",
    "\n",
    "    # Display the frame\n",
    "    cv2.imshow(\"Reverse Video\", frame)\n",
    "\n",
    "    # Wait for a short delay (e.g., 25 ms) to simulate video playback\n",
    "    if cv2.waitKey(25) & 0xFF == ord('q'):  # Press 'q' to quit\n",
    "        break\n",
    "\n",
    "# Release the video capture object and close the display window\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ff8c697-dce4-4c5e-a5f3-66e5d125f006",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
